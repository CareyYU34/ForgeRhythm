<!doctype html>
<html lang="zh-Hant">
  <head>
    <meta charset="utf-8" />
    <title>MediaPipe 動作驗證</title>
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="stylesheet" href="styles.css" />
    <link
      rel="stylesheet"
      href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css"
    />
  </head>

  <body>

    <div class="topbar">
      <div class="sound-rack" id="soundRack">
        <div class="rack-row">
          <label for="leftSound">左腿</label>
          <select id="leftSound" class="rack-select"></select>
        </div>

        <div class="rack-row">
          <label for="rightSound">右腿</label>
          <select id="rightSound" class="rack-select"></select>
        </div>
      </div>

      <button id="toggle" class="topbar-btn">開啟鏡頭</button>

      <div class="yt-input-row">
        <input id="ytUrl" class="yt-url" placeholder="youtube 連結輸入" />
        <button id="ytLoadBtn" class="yt-load-btn">載入</button>
      </div>
    </div>
    
    <div class="layout">
      <div class="stage">
        <video id="webcam" autoplay playsinline></video>
        <canvas id="output"></canvas>
      </div>

      <div id="ytPanel" class="player-card is-hidden">
        <div class="video-wrapper">
          <div class="player" id="player"></div>

          <div class="overlay-play" id="overlayPlay">
            <i class="fas fa-play"></i>
          </div>

          <div class="controls-bar">
            <button id="playPauseBtn" class="btn">
              <i class="fas fa-play"></i>
            </button>

            <div class="volume-container">
              <button id="muteBtn" class="btn">
                <i class="fas fa-volume-high"></i>
              </button>
              <input
                type="range"
                id="volumeSlider"
                min="0"
                max="100"
                value="100"
                class="slider volume"
              />
            </div>

            <select id="playbackSpeed" class="control-select">
              <option value="0.5">0.5x</option>
              <option value="0.75">0.75x</option>
              <option value="1" selected>1x</option>
              <option value="1.25">1.25x</option>
              <option value="1.5">1.5x</option>
              <option value="2">2x</option>
            </select>

            <span class="time">
              <span id="currentTime">0:00</span> /
              <span id="duration">0:00</span>
            </span>

            <div class="seek-container">
              <input
                type="range"
                id="seekBar"
                min="0"
                max="100"
                value="0"
                class="slider seek"
              />
            </div>

            <button id="fullscreenBtn" class="fullscreen-btn">
              <i class="fas fa-expand"></i>
            </button>
          </div>
        </div>
      </div>
    </div>

    <script src="./youtube.js"></script>
    <script src="./math.js"></script>
    <script src="./conditions.js"></script>
    <script src="https://www.youtube.com/iframe_api"></script>

    <script type="module">
      import {
        PoseLandmarker,
        FilesetResolver,
        DrawingUtils,
      } from "https://cdn.skypack.dev/@mediapipe/tasks-vision@0.10.11";

      const video = document.getElementById("webcam");
      const canvas = document.getElementById("output");
      const canvasCtx = canvas.getContext("2d");
      const drawingUtils = new DrawingUtils(canvasCtx);
      const button = document.getElementById("toggle");

      let poseLandmarker = null;
      let running = false;
      let runningMode = "IMAGE";
      let rafId = null;
      let stream = null;
      let preSec = 0;
      let lastVideoTime = -1;
      let leftThighCordon = null;
      let rightThighCordon = null;
      let rightState = {
        pfEma: null,
        prevPfEma: null,
        dpf: 0,
        armed: false,
        lastHitMs: -Infinity,
      };
      let leftState = {
        pfEma: null,
        prevPfEma: null,
        dpf: 0,
        armed: false,
        lastHitMs: -Infinity,
      };

      async function createPoseLandmarker() {
        const fileset = await FilesetResolver.forVisionTasks(
          "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.11/wasm",
        );

        poseLandmarker = await PoseLandmarker.createFromOptions(fileset, {
          baseOptions: {
            modelAssetPath: "./Model/pose_landmarker_full.task",
            delegate: "GPU",
          },
          runningMode,
          numPoses: 1,
          minPoseDetectionConfidence: 0.5,
          minPosePresenceConfidence: 0.5,
          minTrackingConfidence: 0.5,
          outputSegmentationMasks: false,
        });
      }
      createPoseLandmarker();

      async function startWebcam() {
        stream = await navigator.mediaDevices.getUserMedia({
          video: {
            facingMode: "user",
            width: { ideal: 720 },
            height: { ideal: 1280 },
            aspectRatio: 9 / 16,
          },
          audio: false,
        });
        video.srcObject = stream;
        console.log("Webcam started");
        video.addEventListener("loadeddata", predictWebcam);
        video.addEventListener("loadedmetadata", () => {
          canvas.width = video.videoWidth;
          canvas.height = video.videoHeight;
        });
        await initAudio();
      }

      function stopWebcam() {
        if (rafId) cancelAnimationFrame(rafId);
        canvasCtx.clearRect(0, 0, canvas.width, canvas.height);
        if (stream) {
          stream.getTracks().forEach((t) => t.stop());
          stream = null;
        }
        video.srcObject = null;
        lastVideoTime = -1;
        preSec = 0;
        rightState = {
          pfEma: null,
          prevPfEma: null,
          dpf: 0,
          armed: false,
          lastHitMs: -Infinity,
        };
        leftState = {
          pfEma: null,
          prevPfEma: null,
          dpf: 0,
          armed: false,
          lastHitMs: -Infinity,
        };

        console.log("Webcam stopped");
      }

      function drawPose(x) {
        const THREE_POINT_CONNECTIONS = [
          // { start: 0, end: 1 }, //hip -> index
          // { start: 1, end: 2 }, //index -> knee
          { start: 0, end: 2 }, //hip -> knee
        ];
        drawingUtils.drawLandmarks(x, { color: "red", radius: 15 });
        drawingUtils.drawConnectors(x, THREE_POINT_CONNECTIONS);
      }

      //音效初始化
      let audioCtx = null;
      const PLAY_SLOT_INDEX = 0;
      const buffers = new Map();
      const SOUND_LIBRARY = [
        {
          id: "snare",
          label: "小鼓 Snare",
          url: "./sounds/38_Standard Snare 1_v1.wav",
        },
        {
          id: "kick",
          label: "大鼓 Kick",
          url: "./sounds/36_Standard Kick 3.wav",
        },
        {
          id: "hihat",
          label: "Hi-hat",
          url: "./sounds/42_Hi-Hat Closed Soft.wav",
        },
      ];

      const legSound = {
        left: "snare",
        right: "hihat",
      };

      async function loadBuffer(id, url) {
        const res = await fetch(url);
        const arr = await res.arrayBuffer();
        const buf = await audioCtx.decodeAudioData(arr);
        buffers.set(id, buf);
      }

      async function initAudio() {
        if (!audioCtx)
          audioCtx = new (window.AudioContext || window.webkitAudioContext)({
            latencyHint: "interactive",
          });

        if (audioCtx.state === "suspended")
          await audioCtx.resume().catch(() => {});
        await Promise.all(SOUND_LIBRARY.map((s) => loadBuffer(s.id, s.url)));
      }

      function playLeg(leg) {
        if (!audioCtx) return;
        const id = legSound[leg];
        const buf = buffers.get(id);
        if (!buf) return;
        const src = audioCtx.createBufferSource();
        src.buffer = buf;
        src.connect(audioCtx.destination);
        src.start(audioCtx.currentTime);
      }

      function populateSelect(selectEl, selectedId) {
        selectEl.innerHTML = "";
        for (const s of SOUND_LIBRARY) {
          const opt = document.createElement("option");
          opt.value = s.id;
          opt.textContent = s.label;
          if (s.id === selectedId) opt.selected = true;
          selectEl.appendChild(opt);
        }
      }

      function bindSoundUI() {
        const leftSel = document.getElementById("leftSound");
        const rightSel = document.getElementById("rightSound");

        populateSelect(leftSel, legSound.left);
        populateSelect(rightSel, legSound.right);

        leftSel.addEventListener(
          "change",
          () => (legSound.left = leftSel.value),
        );
        rightSel.addEventListener(
          "change",
          () => (legSound.right = rightSel.value),
        );
      }

      bindSoundUI();

      function skipPoints(points, threshold = 0.8) {
        for (const p of points) {
          if (p.visibility < threshold) {
            console.log("Skip due to low visibility:", p.visibility);
            return true;
          }
        }
        return false;
      }

      async function predictWebcam() {
        if (runningMode !== "VIDEO") {
          runningMode = "VIDEO";
          await poseLandmarker.setOptions({ runningMode: "VIDEO" });
        }

        const videoTimeSec = video.currentTime;
        const webTimeMs = performance.now();

        if (videoTimeSec !== lastVideoTime) {
          lastVideoTime = video.currentTime;
          poseLandmarker.detectForVideo(video, webTimeMs, (result) => {
            canvasCtx.clearRect(0, 0, canvas.width, canvas.height);
            if (result.landmarks.length > 0) {
              const pickedLeftHand = [
                result.landmarks[0][23],
                result.landmarks[0][19],
                result.landmarks[0][25],
              ]; //hip, index, knee
              const pickedRightHand = [
                result.landmarks[0][24],
                result.landmarks[0][20],
                result.landmarks[0][26],
              ]; //hip, index, knee

              if (skipPoints(pickedLeftHand) || skipPoints(pickedRightHand)) {
                return;
              }

              drawPose(pickedLeftHand);
              drawPose(pickedRightHand);
              //計算大腿線距離
              leftThighCordon = thighLineDistance(pickedLeftHand);
              rightThighCordon = thighLineDistance(pickedRightHand);

              if (leftThighCordon.T <= 0 || leftThighCordon.T >= 1) {
                leftThighCordon = changePT(leftThighCordon, pickedLeftHand);
              }
              if (rightThighCordon.T <= 0 || rightThighCordon.T >= 1) {
                rightThighCordon = changePT(rightThighCordon, pickedRightHand);
              }

              //監控觸發條件
              const dtSec = videoTimeSec - preSec; //計算手部速度
              preSec = videoTimeSec;
              const PF_WARN = 0.8; //警戒區
              const PF_HIT = 0.6; //命中區
              const DPF_HIT = 0.8; //先給起點，之後調
              const COOLDOWN_MS = 90; //避免一次打擊連發

              rightState = monitoringTriggerConditions(
                rightState,
                rightThighCordon,
                dtSec,
                PF_WARN,
                PF_HIT,
                DPF_HIT,
                webTimeMs,
                COOLDOWN_MS,
              );

              leftState = monitoringTriggerConditions(
                leftState,
                leftThighCordon,
                dtSec,
                PF_WARN,
                PF_HIT,
                DPF_HIT,
                webTimeMs,
                COOLDOWN_MS,
              );

              if (leftState.didHit) playLeg("left");
              if (rightState.didHit) playLeg("right");
            }
          });
        }
        rafId = requestAnimationFrame(predictWebcam);
      }

      button.onclick = async () => {
        if (!poseLandmarker) return;
        running = !running;
        button.textContent = running ? "關閉鏡頭" : "開啟鏡頭";

        if (running) {
          await startWebcam();
        } else {
          stopWebcam();
        }
      };
    </script>
  </body>
</html>
